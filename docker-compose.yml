version: '3.8'

services:
  backend:
    build:
      context: ./backend
    container_name: cautious_backend
    environment:
      - REDIS_URL=redis://redis:6379/0
      - OPENAI_API_BASE=http://ai-engine:8080/v1
      - OPENAI_API_KEY=sk-no-key-required
      - MODEL_NAME=openforecaster
    depends_on:
      - redis
      - ai-engine
    networks:
      - polynet

  frontend:
    build:
      context: ./frontend
    container_name: cautious_frontend
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=/api
      - BACKEND_URL=http://backend:8000
    depends_on:
      - backend
    networks:
      - polynet

  redis:
    image: redis:alpine
    container_name: cautious_redis
    networks:
      - polynet

  ai-engine:
    image: ghcr.io/ggml-org/llama.cpp:server
    container_name: cautious_ai_engine
    volumes:
      - ./models:/models
    command: -m /models/openforecaster.gguf -c 2048 --host 0.0.0.0 --port 8080 --parallel 4
    networks:
      - polynet

networks:
  polynet:
    driver: bridge
